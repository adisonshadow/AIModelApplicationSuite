import OpenAI from 'openai';
import { AIModelConfig, AIProvider, AIModelSender, ChatMessage, SendOptions, ChatResponse, ChatStreamResponse, CompletionResponse, CompletionStreamResponse } from '../types';
import { AutoContinueManager } from '../utils/AutoContinueManager';

export class VolcengineAISender implements AIModelSender {
  private client: OpenAI;
  private config: AIModelConfig;

  constructor(config: AIModelConfig) {
    this.config = config;
    
    // æ”¯æŒ OpenAI å’Œ Volcengine
    if (config.provider === AIProvider.VOLCENGINE || config.provider === AIProvider.OPENAI) {
      this.client = new OpenAI({
        apiKey: config.config?.apiKey || '',
        baseURL: config.config?.baseURL || 'https://ark.cn-beijing.volces.com/api/v3',
        dangerouslyAllowBrowser: true, // å…è®¸åœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨
      });
    } else {
      throw new Error(`ä¸æ”¯æŒçš„ AI æä¾›å•†: ${config.provider}`);
    }
  }

  async sendChatMessage(messages: ChatMessage[], options?: SendOptions): Promise<ChatResponse> {
    const autoContinueManager = AutoContinueManager.getInstance();
    const autoContinueState = autoContinueManager.initializeAutoContinue(options);
    
    let accumulatedContent = '';
    let currentMessages = [...messages];
    let finalResponse: any = null;

    try {
      // æ‰§è¡Œè‡ªåŠ¨ç»§ç»­å¾ªç¯
      while (autoContinueManager.canContinue()) {
        // è§£æé¢å¤–çš„ JSON å‚æ•°
        let extraParams: any = {};
        if (this.config.config?.jsonParams) {
          try {
            extraParams = JSON.parse(this.config.config.jsonParams);
          } catch (error) {
            console.warn('è§£æé¢å¤– JSON å‚æ•°å¤±è´¥:', error);
          }
        }

        const response = await this.client.chat.completions.create({
          model: options?.model || this.config.config?.model || 'deepseek-v3-1-250821',
          messages: currentMessages.map(msg => ({
            role: msg.role as 'system' | 'user' | 'assistant',
            content: msg.content
          })),
          temperature: options?.temperature || extraParams.temperature || 0.7,
          max_tokens: options?.maxTokens || extraParams.max_tokens || 1000,
          top_p: options?.topP || extraParams.top_p || 1,
          frequency_penalty: options?.frequencyPenalty || extraParams.frequency_penalty || 0,
          presence_penalty: options?.presencePenalty || extraParams.presence_penalty || 0,
          ...extraParams
        });

        const choice = response.choices[0];
        if (!choice || !choice.message) {
          throw new Error('AI å“åº”æ ¼å¼é”™è¯¯');
        }

        const responseContent = choice.message.content || '';
        
        // åˆå¹¶å†…å®¹
        accumulatedContent = autoContinueManager.mergeResponseContent(responseContent);
        
        // ä¿å­˜æœ€ç»ˆå“åº”
        finalResponse = {
          id: response.id,
          model: response.model,
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: accumulatedContent
            },
            finishReason: choice.finish_reason || 'stop'
          }],
          usage: {
            promptTokens: response.usage?.prompt_tokens || 0,
            completionTokens: response.usage?.completion_tokens || 0,
            totalTokens: response.usage?.total_tokens || 0
          },
          created: response.created,
          autoContinueState: autoContinueState
        };

        // æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
        if (!autoContinueManager.isResponseInterrupted(response)) {
          console.log('âœ… å“åº”å®Œæˆï¼Œæ— éœ€ç»§ç»­');
          break;
        }

        // å¦‚æœå¯ä»¥ç»§ç»­ï¼Œç”Ÿæˆç»§ç»­æ¶ˆæ¯
        if (autoContinueManager.canContinue()) {
          autoContinueManager.incrementAttempt();
          currentMessages = autoContinueManager.generateContinueMessage(messages, accumulatedContent);
          console.log('ğŸ”„ å‡†å¤‡ç»§ç»­è¯·æ±‚ï¼Œå°è¯•æ¬¡æ•°:', autoContinueManager.getCurrentState()?.currentAttempt);
        }
      }

      // å®Œæˆè‡ªåŠ¨ç»§ç»­
      const finalContent = autoContinueManager.completeAutoContinue();
      
      if (finalResponse) {
        finalResponse.choices[0].message.content = finalContent;
      }

      return finalResponse || {
        id: 'error',
        model: this.config.config?.model || 'unknown',
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: accumulatedContent || 'å“åº”å¤±è´¥'
          },
          finishReason: 'error'
        }],
        usage: {
          promptTokens: 0,
          completionTokens: 0,
          totalTokens: 0
        },
        created: Math.floor(Date.now() / 1000)
      };

    } catch (error) {
      console.error('å‘é€èŠå¤©æ¶ˆæ¯å¤±è´¥:', error);
      autoContinueManager.reset();
      throw error;
    }
  }

  async sendChatMessageStream(messages: ChatMessage[], options?: SendOptions, onUpdate?: (chunk: any) => void): Promise<ChatStreamResponse> {
    const autoContinueManager = AutoContinueManager.getInstance();
    const autoContinueState = autoContinueManager.initializeAutoContinue(options);
    
    let accumulatedContent = '';
    let currentMessages = [...messages];
    let attemptCount = 0;
    let finalResponse: any = null;

    try {
      while (true) {
        attemptCount++;
        console.log(`ğŸ”„ å¼€å§‹ç¬¬ ${attemptCount} æ¬¡è¯·æ±‚`);
        // è§£æé¢å¤–çš„ JSON å‚æ•°
        let extraParams: any = {};
        if (this.config.config?.jsonParams) {
          try {
            extraParams = JSON.parse(this.config.config.jsonParams);
          } catch (error) {
            console.warn('è§£æé¢å¤– JSON å‚æ•°å¤±è´¥:', error);
          }
        }

        const response = await this.client.chat.completions.create({
          model: options?.model || this.config.config?.model || 'deepseek-v3-1-250821',
          messages: currentMessages.map(msg => ({
            role: msg.role as 'system' | 'user' | 'assistant',
            content: msg.content
          })),
          temperature: options?.temperature || extraParams.temperature || 0.7,
          max_tokens: options?.maxTokens || extraParams.max_tokens || 1000,
          top_p: options?.topP || extraParams.top_p || 1,
          frequency_penalty: options?.frequencyPenalty || extraParams.frequency_penalty || 0,
          presence_penalty: options?.presencePenalty || extraParams.presence_penalty || 0,
          stream: true,
          ...extraParams
        });

        // å¤„ç†æµå¼å“åº” - å®æ—¶å¤„ç†æ¯ä¸ª chunk
        let fullContent = '';
        let responseId = '';
        let model = response.model;
        let created = Math.floor(Date.now() / 1000);
        let finishReason = 'stop';

        for await (const chunk of response as any) {
          console.log('ğŸ”„ æ”¶åˆ°åŸå§‹æµå¼æ•°æ®å—:', chunk);
          
          if (chunk.id) responseId = chunk.id;
          
          if (chunk.choices && chunk.choices.length > 0) {
            chunk.choices.forEach((choice: any) => {
              if (choice.delta && choice.delta.content) {
                fullContent += choice.delta.content;
                console.log('ğŸ“ ç´¯ç§¯å†…å®¹:', fullContent);
                
                // å®æ—¶è°ƒç”¨ onUpdate å›è°ƒï¼Œä¼ é€’ç´¯ç§¯å†…å®¹
                if (onUpdate) {
                  const accumulatedChunk = {
                    id: responseId,
                    model: model,
                    choices: [{
                      index: 0,
                      delta: {
                        role: 'assistant',
                        content: fullContent // ä¼ é€’ç´¯ç§¯å†…å®¹ï¼Œä¸æ˜¯å¢é‡å†…å®¹
                      },
                      finishReason: choice.finish_reason
                    }],
                    created: created,
                    autoContinueState: autoContinueState
                  };
                  onUpdate(accumulatedChunk);
                }
              }
              if (choice.finish_reason) {
                finishReason = choice.finish_reason;
                console.log('ğŸ æµå¼å®Œæˆï¼ŒåŸå› :', choice.finish_reason);
              }
            });
          }
        }

        // åˆå¹¶å†…å®¹
        accumulatedContent = autoContinueManager.mergeResponseContent(fullContent);
        
        // ä¿å­˜æœ€ç»ˆå“åº”ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æˆ–å†…å®¹æœ‰å˜åŒ–æ—¶æ›´æ–°ï¼‰
        if (!finalResponse) {
          finalResponse = {
            id: responseId,
            model: model,
            choices: [{
              index: 0,
              delta: {
                role: 'assistant',
                content: accumulatedContent
              },
              finishReason: finishReason
            }],
            created: created,
            autoContinueState: autoContinueState
          };
        } else {
          // æ›´æ–°ç°æœ‰å“åº”çš„å†…å®¹
          finalResponse.choices[0].delta.content = accumulatedContent;
          finalResponse.autoContinueState = autoContinueState;
        }

        // æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
        const mockResponse = {
          choices: [{ 
            finishReason: finishReason,
            message: { content: accumulatedContent }
          }]
        };
        
        if (!autoContinueManager.isResponseInterrupted(mockResponse)) {
          console.log('âœ… æµå¼å“åº”å®Œæˆï¼Œæ— éœ€ç»§ç»­');
          break;
        }

        // å¦‚æœå¯ä»¥ç»§ç»­ï¼Œç”Ÿæˆç»§ç»­æ¶ˆæ¯
        if (autoContinueManager.canContinue()) {
          autoContinueManager.incrementAttempt();
          currentMessages = autoContinueManager.generateContinueMessage(messages, accumulatedContent);
          console.log('ğŸ”„ å‡†å¤‡ç»§ç»­æµå¼è¯·æ±‚ï¼Œå°è¯•æ¬¡æ•°:', autoContinueManager.getCurrentState()?.currentAttempt);
        }
      }

      // å®Œæˆè‡ªåŠ¨ç»§ç»­
      const finalContent = autoContinueManager.completeAutoContinue();
      
      if (finalResponse) {
        finalResponse.choices[0].delta.content = finalContent;
      }

      return finalResponse || {
        id: 'stream-error-' + Date.now(),
        model: this.config.config?.model || 'unknown',
        choices: [{
          index: 0,
          delta: {
            role: 'assistant',
            content: accumulatedContent || 'æµå¼å“åº”å¤±è´¥'
          },
          finishReason: 'error'
        }],
        created: Math.floor(Date.now() / 1000)
      };

    } catch (error) {
      console.error('å‘é€æµå¼èŠå¤©æ¶ˆæ¯å¤±è´¥:', error);
      autoContinueManager.reset();
      throw error;
    }
  }

  async sendCompletion(prompt: string, options?: SendOptions): Promise<CompletionResponse> {
    try {
      // è§£æé¢å¤–çš„ JSON å‚æ•°
      let extraParams: any = {};
      if (this.config.config?.jsonParams) {
        try {
          extraParams = JSON.parse(this.config.config.jsonParams);
        } catch (error) {
          console.warn('è§£æé¢å¤– JSON å‚æ•°å¤±è´¥:', error);
        }
      }

      const response = await this.client.completions.create({
        model: options?.model || this.config.config?.model || 'deepseek-v3-1-250821',
        prompt,
        temperature: options?.temperature || extraParams.temperature || 0.7,
        max_tokens: options?.maxTokens || extraParams.max_tokens || 1000,
        top_p: options?.topP || extraParams.top_p || 1,
        frequency_penalty: options?.frequencyPenalty || extraParams.frequency_penalty || 0,
        presence_penalty: options?.presencePenalty || extraParams.presence_penalty || 0,
        ...extraParams
      });

      const choice = response.choices[0];
      if (!choice) {
        throw new Error('AI å“åº”æ ¼å¼é”™è¯¯');
      }

      return {
        text: choice.text || '',
        usage: {
          promptTokens: response.usage?.prompt_tokens || 0,
          completionTokens: response.usage?.completion_tokens || 0,
          totalTokens: response.usage?.total_tokens || 0
        }
      };
    } catch (error) {
      console.error('å‘é€è¡¥å…¨è¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }

  async sendCompletionStream(prompt: string, options?: SendOptions): Promise<CompletionStreamResponse> {
    try {
      // è§£æé¢å¤–çš„ JSON å‚æ•°
      let extraParams: any = {};
      if (this.config.config?.jsonParams) {
        try {
          extraParams = JSON.parse(this.config.config.jsonParams);
        } catch (error) {
          console.warn('è§£æé¢å¤– JSON å‚æ•°å¤±è´¥:', error);
        }
      }

      const response = await this.client.completions.create({
        model: options?.model || this.config.config?.model || 'deepseek-v3-1-250821',
        prompt,
        temperature: options?.temperature || extraParams.temperature || 0.7,
        max_tokens: options?.maxTokens || extraParams.max_tokens || 1000,
        top_p: options?.topP || extraParams.top_p || 1,
        frequency_penalty: options?.frequencyPenalty || extraParams.frequency_penalty || 0,
        presence_penalty: options?.presencePenalty || extraParams.presence_penalty || 0,
        stream: true,
        ...extraParams
      });

      let text = '';
      for await (const chunk of response as any) {
        if (chunk.choices && chunk.choices.length > 0) {
          chunk.choices.forEach((choice: any) => {
            if (choice.text) {
              text += choice.text;
            }
          });
        }
      }

      return {
        text,
        done: true
      };
    } catch (error) {
      console.error('å‘é€æµå¼è¡¥å…¨è¯·æ±‚å¤±è´¥:', error);
      throw error;
    }
  }
}
