# AIæ¶ˆæ¯é€‚é…å™¨ (AI Message Adapter)

AIæ¶ˆæ¯é€‚é…å™¨æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£å±‚ï¼Œå…è®¸å¼€å‘äººå‘˜ä½¿ç”¨ç»Ÿä¸€çš„APIä¸ä¸åŒçš„AIæœåŠ¡å•†è¿›è¡Œæ¶ˆæ¯äº¤äº’ï¼Œæ— éœ€å…³å¿ƒåº•å±‚æœåŠ¡å•†çš„å·®å¼‚ã€‚

## ç‰¹æ€§

- ğŸ”„ **ç»Ÿä¸€æ¥å£**: ä½¿ç”¨ç›¸åŒçš„APIä¸ä¸åŒAIæœåŠ¡å•†äº¤äº’
- ğŸš€ **ç®€å•æ˜“ç”¨**: ç®€æ´çš„APIè®¾è®¡ï¼Œå¿«é€Ÿä¸Šæ‰‹
- ğŸ”Œ **å¯æ‰©å±•**: æ”¯æŒæ·»åŠ æ–°çš„AIæœåŠ¡å•†
- ğŸ’¬ **æ¶ˆæ¯æµ**: æ”¯æŒæµå¼å“åº”å’Œæ™®é€šå“åº”
- ğŸ›¡ï¸ **ç±»å‹å®‰å…¨**: å®Œæ•´çš„TypeScriptç±»å‹æ”¯æŒ

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
npm install @your-org/ai-model-sender
```

### åŸºæœ¬ä½¿ç”¨

```typescript
import { createAIModelSender } from '@your-org/ai-model-sender';

// åˆ›å»ºå‘é€å™¨å®ä¾‹
const sender = createAIModelSender({
  provider: 'volcengine', // AIæœåŠ¡å•†
  config: {
    apiKey: 'your-api-key',
    // å…¶ä»–é…ç½®...
  }
});

// å‘é€æ¶ˆæ¯
const response = await sender.sendMessage({
  messages: [
    { role: 'user', content: 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±' }
  ]
});

console.log(response.content);
```

## è¯¦ç»†ä½¿ç”¨æŒ‡å—

### 1. åˆ›å»ºå‘é€å™¨

```typescript
import { createAIModelSender } from '@your-org/ai-model-sender';

// æ–¹å¼1: ä½¿ç”¨é…ç½®å¯¹è±¡
const sender = createAIModelSender({
  provider: 'volcengine',
  config: {
    apiKey: 'your-api-key',
    region: 'cn-beijing',
    model: 'deepseek-v3.1'
  }
});

// æ–¹å¼2: ä½¿ç”¨å·¥å‚å‡½æ•°
const sender = createAIModelSender({
  provider: 'openai',
  config: {
    apiKey: 'your-openai-key',
    baseURL: 'https://api.openai.com/v1',
    model: 'gpt-4'
  }
});
```

### 2. å‘é€æ¶ˆæ¯

#### æ™®é€šæ¶ˆæ¯

```typescript
// å•è½®å¯¹è¯
const response = await sender.sendMessage({
  messages: [
    { role: 'user', content: 'è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½' }
  ]
});

console.log('AIå›å¤:', response.content);
```

#### å¤šè½®å¯¹è¯

```typescript
// å¤šè½®å¯¹è¯
const conversation = [
  { role: 'user', content: 'ä½ å¥½' },
  { role: 'assistant', content: 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ' },
  { role: 'user', content: 'è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ' }
];

const response = await sender.sendMessage({
  messages: conversation
});

console.log('AIå›å¤:', response.content);
```

#### æµå¼å“åº”

```typescript
// æµå¼å“åº”
const stream = await sender.sendMessageStream({
  messages: [
    { role: 'user', content: 'è¯·å†™ä¸€ä¸ªå…³äºæ˜¥å¤©çš„è¯—' }
  ]
});

for await (const chunk of stream) {
  if (chunk.type === 'content') {
    process.stdout.write(chunk.content);
  } else if (chunk.type === 'done') {
    console.log('\nå®Œæˆ');
  }
}
```

### 3. é«˜çº§åŠŸèƒ½

#### è‡ªå®šä¹‰å‚æ•°

```typescript
const response = await sender.sendMessage({
  messages: [
    { role: 'user', content: 'è¯·å†™ä¸€ä¸ªæ•…äº‹' }
  ],
  options: {
    temperature: 0.7,
    maxTokens: 1000,
    topP: 0.9
  }
});
```

#### é”™è¯¯å¤„ç†

```typescript
try {
  const response = await sender.sendMessage({
    messages: [
      { role: 'user', content: 'æµ‹è¯•æ¶ˆæ¯' }
    ]
  });
} catch (error) {
  if (error.code === 'RATE_LIMIT') {
    console.log('è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•');
  } else if (error.code === 'INVALID_API_KEY') {
    console.log('APIå¯†é’¥æ— æ•ˆ');
  } else {
    console.log('å‘é€å¤±è´¥:', error.message);
  }
}
```

## æ”¯æŒçš„æœåŠ¡å•†

### Volcengine (ç«å±±å¼•æ“)

```typescript
const sender = createAIModelSender({
  provider: 'volcengine',
  config: {
    apiKey: 'your-volcengine-key',
    region: 'cn-beijing', // å¯é€‰
    model: 'deepseek-v3.1' // å¯é€‰ï¼Œé»˜è®¤æ¨¡å‹
  }
});
```

### OpenAI

```typescript
const sender = createAIModelSender({
  provider: 'openai',
  config: {
    apiKey: 'your-openai-key',
    baseURL: 'https://api.openai.com/v1', // å¯é€‰
    model: 'gpt-4' // å¯é€‰ï¼Œé»˜è®¤æ¨¡å‹
  }
});
```

### è‡ªå®šä¹‰æœåŠ¡å•†

```typescript
// å®ç°è‡ªå®šä¹‰æœåŠ¡å•†
class CustomProvider implements AIProvider {
  async sendMessage(request: SendMessageRequest): Promise<SendMessageResponse> {
    // å®ç°å‘é€é€»è¾‘
    return {
      content: 'è‡ªå®šä¹‰å›å¤',
      usage: { promptTokens: 10, completionTokens: 5 }
    };
  }

  async sendMessageStream(request: SendMessageRequest): Promise<AsyncIterable<ChatStreamResponse>> {
    // å®ç°æµå¼å‘é€é€»è¾‘
    return this.createStream(request);
  }
}

// æ³¨å†Œè‡ªå®šä¹‰æœåŠ¡å•†
registerProvider('custom', CustomProvider);

// ä½¿ç”¨è‡ªå®šä¹‰æœåŠ¡å•†
const sender = createAIModelSender({
  provider: 'custom',
  config: {
    // è‡ªå®šä¹‰é…ç½®
  }
});
```

## API å‚è€ƒ

### æ ¸å¿ƒæ¥å£

#### `createAIModelSender(config)`

åˆ›å»ºAIæ¶ˆæ¯å‘é€å™¨å®ä¾‹ã€‚

**å‚æ•°:**
- `config.provider`: æœåŠ¡å•†åç§°
- `config.config`: æœåŠ¡å•†é…ç½®

**è¿”å›:** `AIModelSender` å®ä¾‹

#### `sender.sendMessage(request)`

å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤ã€‚

**å‚æ•°:**
- `request.messages`: æ¶ˆæ¯æ•°ç»„
- `request.options`: å¯é€‰å‚æ•° (temperature, maxTokensç­‰)

**è¿”å›:** `Promise<SendMessageResponse>`

#### `sender.sendMessageStream(request)`

å‘é€æ¶ˆæ¯å¹¶è·å–æµå¼å›å¤ã€‚

**å‚æ•°:**
- `request.messages`: æ¶ˆæ¯æ•°ç»„
- `request.options`: å¯é€‰å‚æ•°

**è¿”å›:** `Promise<AsyncIterable<ChatStreamResponse>>`

### ç±»å‹å®šä¹‰

```typescript
interface SendMessageRequest {
  messages: Message[];
  options?: {
    temperature?: number;
    maxTokens?: number;
    topP?: number;
    [key: string]: any;
  };
}

interface SendMessageResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

interface Message {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface ChatStreamResponse {
  type: 'content' | 'done' | 'error';
  content?: string;
  error?: string;
}
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```typescript
const sendMessageWithRetry = async (sender: AIModelSender, request: SendMessageRequest, maxRetries = 3) => {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await sender.sendMessage(request);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
};
```

### 2. æ¶ˆæ¯ç®¡ç†

```typescript
class ConversationManager {
  private messages: Message[] = [];

  addMessage(role: 'user' | 'assistant', content: string) {
    this.messages.push({ role, content });
  }

  async sendMessage(sender: AIModelSender, content: string) {
    this.addMessage('user', content);
    
    const response = await sender.sendMessage({
      messages: this.messages
    });
    
    this.addMessage('assistant', response.content);
    return response;
  }

  clear() {
    this.messages = [];
  }
}
```

### 3. æµå¼å¤„ç†

```typescript
const handleStream = async (stream: AsyncIterable<ChatStreamResponse>) => {
  let fullContent = '';
  
  for await (const chunk of stream) {
    switch (chunk.type) {
      case 'content':
        fullContent += chunk.content;
        process.stdout.write(chunk.content);
        break;
      case 'done':
        console.log('\nå®Œæˆ');
        break;
      case 'error':
        console.error('æµå¼é”™è¯¯:', chunk.error);
        break;
    }
  }
  
  return fullContent;
};
```

## ç¤ºä¾‹é¡¹ç›®

æŸ¥çœ‹ `examples/AIModelSender/App.tsx` è·å–å®Œæ•´çš„ç¤ºä¾‹ä»£ç ï¼ŒåŒ…æ‹¬ï¼š

- åŸºæœ¬çš„æ¶ˆæ¯å‘é€
- æµå¼å“åº”å¤„ç†
- é”™è¯¯å¤„ç†
- UIç•Œé¢æ¼”ç¤º

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## è®¸å¯è¯

MIT License
